import os
import argparse
import numpy as np
import pandas as pd
import scanpy as sc
from pyspark.sql import SparkSession, functions as f

class PseudobulkExpression:
    @property
    def spark(self):
        if self._spark is None:
            self._spark = SparkSession.builder.appName("PseudobulkJSON").getOrCreate()
        return self._spark
    """
    Process cellxgene formatted single-cell AnnData into pseudobulked
    JSON per gene, matching the unaggregated schema.
    This class reads an AnnData object, filters it, normalizes it,
    and then aggregates the data into pseudobulk format.
    It also generates a translation map for tissue and cell type annotations.
    """

    def __init__(self, h5ad_path, datasource_id, datatype_id, unit, biosample_index_path=None):
        self.h5ad_path     = h5ad_path
        self.datasource_id = datasource_id
        self.datatype_id   = datatype_id
        self.unit          = unit
        self.biosample_index_path = biosample_index_path
        self.biosample_index = None
        if biosample_index_path is not None:
            self.biosample_index = pd.read_csv(biosample_index_path, sep='\t')
        self._spark = None  # Lazy initialization

    def read_h5ad(self):
        print(f"Reading h5ad file: {self.h5ad_path}")
        self.adata = sc.read(self.h5ad_path)
        self.adata.var_names_make_unique()
        self.adata.strings_to_categoricals()
        if self.adata.var.index.name != 'ensg':
            raise ValueError(f"Expected var index name 'ensg', got '{self.adata.var.index.name}'")

    def filter_anndata(self, min_cells=0, min_genes=0, method='10X'):
        if min_genes > 0:
            sc.pp.filter_cells(self.adata, min_genes=min_genes)
        if min_cells > 0:
            sc.pp.filter_genes(self.adata, min_cells=min_cells)
        print(f"Keeping only cells generated by {method}")
        self.adata = self.adata[self.adata.obs['method'] == method]

    def normalise_anndata(self, method='logCP10K'):
        """
        Normalise the AnnData object using the specified method.

        Parameters
        ----------
        method : str, default 'logCP10K'
            The normalization method to use. If the method matches a key in
            AnnData.layers, that layer is used as the normalized data.
            If 'logCP10K', the data is normalized to a total count of 10,000 per cell
            and log-transformed using scanpy's normalize_total and log1p functions.
        """
        print(f"Normalising data using {method}")
        if method in self.adata.layers:
            self.adata.X = self.adata.layers[method]
        elif method == 'logCP10K':
            sc.pp.normalize_total(self.adata, target_sum=1e4)
            sc.pp.log1p(self.adata)


    def pseudobulk_data(self, donor_colname, min_cells, tissue_agg_colname=None, celltype_agg_colname=None,  method='dMean'):
        adata = self.adata
        if tissue_agg_colname is None and celltype_agg_colname is None:
            raise ValueError("At least one aggregation column must be specified: tissue_agg_colname or celltype_agg_colname")
        elif tissue_agg_colname is not None and celltype_agg_colname is not None:
            # Make a list of tuples for the annotations list that will be looped through e.g.
            # [('liver', 'neuron'), ('liver', 'glia'), ('ileum', 'enterocyte')]
            annotations = adata.obs[[tissue_agg_colname, celltype_agg_colname]].drop_duplicates()
            # Make a list of tuples for each unique combination
            annotations = list(zip(annotations[tissue_agg_colname], annotations[celltype_agg_colname]))
        elif tissue_agg_colname is not None:
            # If only tissue aggregation is specified, use unique tissue annotations
            annotations = adata.obs[tissue_agg_colname].unique()
            # Make into a list of tuples where the second element is None
            annotations = [(annot, None) for annot in annotations]
        elif celltype_agg_colname is not None:
            # If only cell type aggregation is specified, use unique cell type annotations
            annotations = adata.obs[celltype_agg_colname].unique()
            # Make into a list of tuples where the first element is None
            annotations = [(None, annot) for annot in annotations]

        # Ensure the donor column exists
        if donor_colname not in adata.obs.columns:
            raise ValueError(f"Donor column '{donor_colname}' not found in AnnData.obs")
        for annot in annotations:
            print(f"Aggregating {annot}")
            subset = adata
            if tissue_agg_colname:
                subset = subset[subset.obs[tissue_agg_colname] == annot[0]]
            if celltype_agg_colname:
                subset = subset[subset.obs[celltype_agg_colname] == annot[1]]
            agg_df = pd.DataFrame()
            donor_meta = []
            # per-donor aggregation
            for donor in subset.obs[donor_colname].unique():
                mask = subset.obs[donor_colname] == donor
                donor_cells = subset[mask]
                count = donor_cells.shape[0]
                if count < min_cells:
                    continue
                donor_meta.append({
                    'sampleId': donor,
                    'cellCount': count,
                    'sex':   np.nan if 'sex' not in donor_cells.obs else donor_cells.obs['sex'].iat[0],
                    'age':  np.nan if 'age' not in donor_cells.obs else donor_cells.obs['age'].iat[0],
                    'ethnicity' : np.nan if 'self_reported_ethnicity' not in donor_cells.obs else donor_cells.obs['self_reported_ethnicity'].iat[0]
                })
                matrix = donor_cells.to_df()
                vector = matrix.mean(axis=0) if method=='dMean' else matrix.sum(axis=0)
                agg_df = pd.concat([agg_df, pd.DataFrame(vector, columns=[donor])], axis=1)
            # JSON all genes
            self.save_json(agg_df, donor_meta, annot, method,
                           tissue_agg_colname, celltype_agg_colname)
            # JSON per gene
            self.save_json(agg_df, donor_meta, annot, method,
                            tissue_agg_colname, celltype_agg_colname, per_gene=True)

def save_json(self,
              agg_df,
              donor_meta,
              annotation,
              method,
              tissue_agg_colname,
              celltype_agg_colname,
              per_gene=False):
        If per_gene=True, writes one file per gene under
        results/json/{annotation_label}/{method}/{gene}.json
        # 1) wide → Spark DF
        index_name = agg_df.index.name if agg_df.index.name is not None else 'index'
        pdf = agg_df.reset_index().rename(columns={index_name: 'targetId'})
        sdf = self.spark.createDataFrame(pdf)

        # 2) pivot to long: (targetId, sampleId, expression)
        sample_cols = [c for c in pdf.columns if c != 'targetId']
        N = len(sample_cols)
        packed = ", ".join([f"'{c}', `{c}`" for c in sample_cols])
        long_df = sdf.selectExpr(
            "targetId",
            f"stack({N}, {packed}) as (sampleId, expression)"
        )

        # 3) join donor metadata
        meta_df = self.spark.createDataFrame(donor_meta)
        joined = long_df.join(meta_df, on='sampleId', how='left')

        # 4) figure out tissue / celltype IDs and labels
        tissue_id, celltype_id = None, None
        tissue_label, ct_label = None, None

        if tissue_agg_colname:
            tissue_id = annotation[0]
            tissue_label = tissue_id
            # If tissue ID starts with EFO, CLO or UBERON get the label from the biosample index
            if tissue_id.startswith(('EFO', 'CLO', 'UBERON')) and self.biosample_index is not None:
                match = self.biosample_index.loc[self.biosample_index['ontology_term_id'] == tissue_id, 'label']
                if not match.empty:
                    tissue_label = match.values[0]
                
        if celltype_agg_colname:
            celltype_id = annotation[1]
            ct_label = celltype_id
            # If cell type ID starts with CL, UBERON or EFO get the label from the biosample index
            if celltype_id.startswith(('CL', 'UBERON', 'EFO')) and self.biosample_index is not None:
                match = self.biosample_index.loc[self.biosample_index['ontology_term_id'] == celltype_id, 'label']
                if not match.empty:
                    ct_label = match.values[0]

        # 5) add constant columns
        consts = {
            'datasourceId':               self.datasource_id,
            'datatypeId':                 self.datatype_id,
            'unit':                       self.unit,
            'tissueBiosampleId':          tissue_id,
            'celltypeBiosampleId':        celltype_id,
            'tissueBiosampleFromSource':  tissue_label,
            'celltypeBiosampleFromSource':ct_label,
            'targetFromSource':           None
        }
        for k, v in consts.items():
            joined = joined.withColumn(k,  f.lit(v))

        # 6) build the nested struct and aggregate
        expr_struct =  f.struct(
             f.col('expression').alias('expression'),
             f.col('sampleId').alias('sampleId'),
             f.col('cellCount').alias('cellCount'),
             f.col('sex').alias('sex'),
             f.col('ethnicity').alias('ethnicity'),
             f.col('age').alias('age'),
        )
        nested = joined.withColumn('expression', expr_struct)

        group_cols = ['targetId'] + list(consts.keys())
        result = nested.groupBy(*group_cols) \
                       .agg( f.collect_list('expression').alias('expression'))

        # 7) turn to JSON
        json_rdd = result.toJSON()

        # 8) build a friendly annotation label for the path
        parts = []
        if tissue_agg_colname:
            parts.append(tissue_id)
        if celltype_agg_colname:
            parts.append(celltype_id)
        annotation_label = "__".join(parts) or "all"
        annotation_label = annotation_label.replace(":", "_").replace("/", "_")


        base_dir = f'results/json/{annotation_label}/{method}'
        os.makedirs(base_dir, exist_ok=True)

        if per_gene:
            # write one JSON file per gene
            lines = json_rdd.collect()
            genes = result.select('targetId').rdd.flatMap(lambda r: r).collect()
            for gene, line in zip(genes, lines):
                safe = gene.replace('/', '_')
                path = os.path.join(base_dir, f'{safe}.json')
                with open(path, 'w') as outf:
                    outf.write(line)
            print(f"Wrote {len(genes)} per‑gene JSON files to {base_dir}")
        else:
            # write a single JSON file (one line per gene)
            out_path = os.path.join(base_dir, 'pseudobulk.json')
            result.toJSON() \
                  .write \
                  .mode("overwrite") \
                  .text(out_path)
            count = result.count()
            print(f"Wrote JSON with {count} gene records to {out_path}")


    def main(self, args, methods):
        self.read_h5ad()
        self.filter_anndata(args.min_cells, args.min_genes, args.method)
        self.normalise_anndata(args.normalisation_method)
        for m in methods:
            self.pseudobulk_data(
                args.donor_colname,
                args.aggregation_min_cells,
                tissue_agg_colname=args.tissue_agg_colname,
                method=m
            )
            self.pseudobulk_data(
                args.donor_colname,
                args.aggregation_min_cells,
                celltype_agg_colname=args.celltype_agg_colname,
                method=m
            )
            self.pseudobulk_data(
                args.donor_colname,
                args.aggregation_min_cells,
                tissue_agg_colname=args.tissue_agg_colname,
                celltype_agg_colname=args.celltype_agg_colname,
                method=m
            )
        print("Done: pseudobulk + per-gene JSON export.")


    p.add_argument("--h5ad_path", required=True)
    p.add_argument("--min_cells", type=int, default=0)
    p.add_argument("--min_genes", type=int, default=0)
    p.add_argument("--method", type=str, default='10X')
    p.add_argument("--normalisation_method", type=str, default='logCP10K')
    p.add_argument("--donor_colname", type=str, required=True)
    p.add_argument("--aggregation_min_cells", type=int, required=True)
    p.add_argument("--aggregation_method", type=str, default='dMean,dSum')
    p.add_argument("--datasource_id", type=str, required=True)
    p.add_argument("--datatype_id", type=str, default="scrna-seq")
    p.add_argument("--unit", type=str, default="logCP10K")
    p.add_argument("--biosample_index_path", type=str, required=True)
    p.add_argument("--tissue_agg_colname", type=str, default='tissue_ontology_term_id')
    p.add_argument("--celltype_agg_colname", type=str, default='cell_type_ontology_term_id')

    args = p.parse_args()
    methods = args.aggregation_method.split(',') 
    PseudobulkExpression(
        args.h5ad_path,
        datasource_id = args.datasource_id,
        datatype_id   = args.datatype_id,
        unit          = args.unit,
        biosample_index_path = args.biosample_index_path
    ).main(args, methods)
